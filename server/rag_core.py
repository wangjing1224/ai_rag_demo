# æ–‡ä»¶ä½ç½®: server/rag_core.py
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import CharacterTextSplitter
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter  # â• æ–°å¢ï¼šé€’å½’åˆ‡åˆ†å™¨
from langchain_openai import OpenAIEmbeddings   # ğŸ‘ˆ åµŒå…¥æ¨¡å‹
from langchain_openai import ChatOpenAI         # ğŸ‘ˆ èŠå¤©æ¨¡å‹

# â• æ–°å¢ï¼šå¼•å…¥ PDF,word,excel åŠ è½½å™¨
from langchain_community.document_loaders import PyPDFLoader,Docx2txtLoader,UnstructuredExcelLoader

load_dotenv()

# è¿™é‡Œçš„é€»è¾‘å’Œä½ ä¹‹å‰çš„ä¸€æ¨¡ä¸€æ ·ï¼Œåªæ˜¯å°è£…æˆäº†ç±»
class RAGService:
    def __init__(self):
        # # 1. åˆå§‹åŒ–æ¨¡å‹
        # self.llm = ChatOpenAI(
        #     api_key=api_key,
        #     base_url=base_url,
        #     model="deepseek-chat",
        #     temperature=0.1
        # )
        
        # 1. å®šä¹‰ä¸€ä¸ªé…ç½®å­—å…¸ï¼ŒæŠŠæ‰€æœ‰æ¨¡å‹çš„â€œèº«ä»½è¯â€éƒ½ç™»è®°åœ¨è¿™é‡Œ
        # è¿™æ ·ä»¥åæƒ³åŠ æ–°æ¨¡å‹ï¼Œåªéœ€è¦æ”¹è¿™é‡Œï¼Œä¸ç”¨åŠ¨ä¸šåŠ¡é€»è¾‘
        self.model_config = {
            # === DeepSeek ç³»åˆ— ===
            "deepseek-chat": {
                "api_key": os.getenv("DEEPSEEK_API_KEY"),
                "base_url": os.getenv("DEEPSEEK_BASE_URL"),
                "temperature": 0.3
            },
            "deepseek-reasoner": {
                "api_key": os.getenv("DEEPSEEK_API_KEY"),
                "base_url": os.getenv("DEEPSEEK_BASE_URL"),
                "temperature": 0.1 # æ¨ç†æ¨¡å‹é€šå¸¸ä½æ¸©
            },
            
            # === é˜¿é‡Œäº‘é€šä¹‰åƒæ–‡ç³»åˆ— ===
            "qwen-plus": {
                "api_key": os.getenv("QWEN_API_KEY"),
                "base_url": os.getenv("QWEN_BASE_URL"),
                "temperature": 0.5
            },
            "qwen-max": { # é€šä¹‰åƒæ–‡æœ€å¼ºç‰ˆ
                "api_key": os.getenv("QWEN_API_KEY"),
                "base_url": os.getenv("QWEN_BASE_URL"),
                "temperature": 0.5
            },

            # === OpenAI ç³»åˆ— ===
            "gpt-4o": {
                "api_key": os.getenv("OPENAI_API_KEY"),
                "base_url": os.getenv("OPENAI_BASE_URL"),
                "temperature": 0.7
            }
        }
        
        # é»˜è®¤åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹ (é˜²æ­¢å¯åŠ¨æŠ¥é”™)
        self.current_llm = self._create_llm("deepseek-chat")   
        
        print("æ­£åœ¨åŠ è½½æœ¬åœ°åµŒå…¥æ¨¡å‹ (é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸‹è½½)...")
        self.embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2") 
        # âœ… ä½¿ç”¨è¿™ä¸ªï¼å®ƒä¼šä¸‹è½½ä¸€ä¸ªå°æ¨¡å‹åˆ°ä½ ç”µè„‘ä¸Šï¼Œä¸ç”¨è”ç½‘ä¹Ÿèƒ½è·‘
        self.vector_store_path = "faiss_index" # ğŸ’¾ ç´¢å¼•ä¿å­˜è·¯å¾„
        self.vector_store = self._load_vector_store() # ğŸ”„ å¯åŠ¨æ—¶å°è¯•åŠ è½½
    
    # ğŸ› ï¸ å·¥å‚æ–¹æ³•ï¼šä¸“é—¨è´Ÿè´£ç”Ÿäº§ LLM å¯¹è±¡
    def _create_llm(self, model_name):
        config = self.model_config.get(model_name)
        if not config:
            raise ValueError(f"âš ï¸ æ¨¡å‹ {model_name} çš„ API Key æœªé…ç½®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
        
        print(f"ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹: {model_name} (URL: {config['base_url']})")
        
        return ChatOpenAI(
            api_key=config["api_key"],
            base_url=config["base_url"],
            model=model_name,
            temperature=config.get("temperature", 0.3)
        )
        
    # ğŸ”„ å†…éƒ¨æ–¹æ³•ï¼šå°è¯•ä»ç¡¬ç›˜åŠ è½½ç´¢å¼•
    def _load_vector_store(self):
        if os.path.exists(self.vector_store_path):
            try:
                # allow_dangerous_deserialization=True æ˜¯ä¸ºäº†åŠ è½½æœ¬åœ° pickle æ–‡ä»¶
                vs = FAISS.load_local(self.vector_store_path, self.embeddings, allow_dangerous_deserialization=True)
                print("âœ… [RAG] æˆåŠŸåŠ è½½æœ¬åœ°ç´¢å¼•ï¼")
                return vs
            except Exception as e:
                print(f"âš ï¸ [RAG] åŠ è½½ç´¢å¼•å¤±è´¥ï¼Œå°†é‡å»º: {e}")
                return None
        return None

    # ğŸ’¾ å†…éƒ¨æ–¹æ³•ï¼šä¿å­˜ç´¢å¼•åˆ°ç¡¬ç›˜
    def _save_vector_store(self):
        if self.vector_store:
            self.vector_store.save_local(self.vector_store_path)
            print("ğŸ’¾ [RAG] ç´¢å¼•å·²ä¿å­˜åˆ°æœ¬åœ°")
    
    # 1. ä¿ç•™åŸæ¥çš„å­—ç¬¦ä¸²åˆå§‹åŒ–æ–¹æ³• (ä¸ºäº†å…¼å®¹)
    def init_from_text(self, text_content):
        text_splitter = CharacterTextSplitter(separator="\n", chunk_size=100, chunk_overlap=10)
        docs = [Document(page_content=x) for x in text_splitter.split_text(text_content)]
        self.vector_store = FAISS.from_documents(docs, self.embeddings)
        print("âœ… æ–‡æœ¬çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ")

    # ğŸ”„ [é‡æ„] è¿™æ˜¯ä¸€ä¸ªå†…éƒ¨é€šç”¨æ–¹æ³•ï¼Œä¸ç®¡ä»€ä¹ˆæ–‡ä»¶ï¼Œè¯»å‡ºæ¥åéƒ½èµ°è¿™å¥—æµç¨‹
    def _proccess_and_save(self, docs,file_path):
        print(f"âœ… æˆåŠŸåŠ è½½ {len(docs)} é¡µ æ–‡æ¡£")
        
        # ç»Ÿä¸€ä½¿ç”¨é…ç½®å¥½çš„åˆ‡åˆ†å™¨
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        split_docs = splitter.split_documents(docs)
        print(f"âœ… åˆ‡åˆ†æˆ {len(split_docs)} çŸ¥è¯†ç‰‡æ®µ")
        
        if self.vector_store:
            self.vector_store.add_documents(split_docs)
            print("âœ… å·²ç»è¿½åŠ åˆ°ç°æœ‰çŸ¥è¯†åº“")
        else:
            self.vector_store = FAISS.from_documents(split_docs, self.embeddings)
            print("âœ… åˆå§‹åŒ–äº†æ–°çš„çŸ¥è¯†åº“")  
            
        self._save_vector_store()
        print(f"âœ… æ–‡ä»¶ '{os.path.basename(file_path)}' å·²æˆåŠŸæ·»åŠ åˆ°çŸ¥è¯†åº“ï¼") 
        
    # 2. æ–°å¢ï¼šæ·»åŠ  PDF æ–‡ä»¶åˆ°çŸ¥è¯†åº“,è°ƒç”¨ä¸Šé¢çš„é€šç”¨æ–¹æ³•    
    def add_pdf(self, file_path):
        # try:
        #     #åŠ è½½ PDF æ–‡ä»¶
        #     loader = PyPDFLoader(file_path)
        #     docs = loader.load()
        #     print(f"âœ… æˆåŠŸåŠ è½½ {len(docs)} é¡µ PDF")
            
        #     #åˆ‡åˆ†æ–‡æ¡£
        #     # ğŸ’¡ çŸ¥è¯†ç‚¹ï¼šchunk_size è¶Šå°ï¼Œæ£€ç´¢è¶Šç²¾å‡†ï¼Œä½†ä¸¢å¤±ä¸Šä¸‹æ–‡ï¼›è¶Šå¤§ï¼Œä¸Šä¸‹æ–‡å®Œæ•´ï¼Œä½†å™ªéŸ³å¤šã€‚
        #     splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        #     split_docs = splitter.split_documents(docs)
        #     print(f"âœ… åˆ‡åˆ†æˆ {len(split_docs)} çŸ¥è¯†ç‰‡æ®µ")
            
        #     #åŠ å…¥åˆ°å‘é‡åº“(å†…å­˜ä¸­)
        #     if self.vector_store:
        #         self.vector_store.add_documents(split_docs)
        #         print("âœ… å·²ç»è¿½åŠ åˆ°ç°æœ‰çŸ¥è¯†åº“")
        #     else:
        #         self.vector_store = FAISS.from_documents(split_docs, self.embeddings)
        #         print("âœ… åˆå§‹åŒ–äº†æ–°çš„çŸ¥è¯†åº“")
                
        #     #ä¿å­˜åˆ°æœ¬åœ°
        #     self._save_vector_store()
        #     print(f"âœ… æ–‡ä»¶ '{os.path.basename(file_path)}' å·²æˆåŠŸæ·»åŠ åˆ°çŸ¥è¯†åº“ï¼")
        # except Exception as e:
        #     print(f"âŒ æ·»åŠ æ–‡ä»¶å¤±è´¥: {e}")
        #     raise e # æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿ä¸Šå±‚å¤„ç†    
        print(f"æ­£åœ¨å¤„ç† PDF æ–‡ä»¶: {file_path}")
        try:
            # åŠ è½½ PDF æ–‡ä»¶
            loader = PyPDFLoader(file_path)
            docs = loader.load()
            self._proccess_and_save(docs,file_path)
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡ä»¶å¤±è´¥: {e}")
            raise e  # æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿ä¸Šå±‚å¤„ç†
         
    # â• æ–°å¢ï¼šæ·»åŠ  Word æ–‡ä»¶åˆ°çŸ¥è¯†åº“,è°ƒç”¨ä¸Šé¢çš„é€šç”¨æ–¹æ³•
    def add_word(self, file_path):
        print(f"æ­£åœ¨å¤„ç† Word æ–‡ä»¶: {file_path}")
        try:
            # åŠ è½½ Word æ–‡ä»¶
            loader = Docx2txtLoader(file_path)
            docs = loader.load()
            self._proccess_and_save(docs,file_path)
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡ä»¶å¤±è´¥: {e}")
            raise e  # æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿ä¸Šå±‚å¤„ç†
    
    # â• æ–°å¢ï¼šæ·»åŠ  Excel æ–‡ä»¶åˆ°çŸ¥è¯†åº“,è°ƒç”¨ä¸Šé¢çš„é€šç”¨æ–¹æ³•
    def add_excel(self, file_path):
        print(f"æ­£åœ¨å¤„ç† Excel æ–‡ä»¶: {file_path}")
        try:
            # åŠ è½½ Excel æ–‡ä»¶
            #mode="elements" æŒ‰è¡ŒåŠ è½½ï¼Œæ›´é€‚åˆè¡¨æ ¼
            loader = UnstructuredExcelLoader(file_path,mode="elements")
            docs = loader.load()
            self._proccess_and_save(docs,file_path)
        except Exception as e:
            print(f"âŒ æ·»åŠ æ–‡ä»¶å¤±è´¥: {e}")
            raise e  # æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿ä¸Šå±‚å¤„ç†
              
    #ğŸ†• æ–°å¢ï¼šåˆ é™¤æ–‡ä»¶ï¼ˆé€šè¿‡é‡å»ºç´¢å¼•çš„æ–¹å¼ï¼Œè¿™æ˜¯æœ€ç®€å•ç¨³å¦¥çš„æ–¹æ³•ï¼‰
    def delete_file(self, filename):
        # if not self.vector_store:
        #     print("âš ï¸ çŸ¥è¯†åº“ä¸ºç©ºï¼Œæ— éœ€åˆ é™¤")
        #     return
        
        # # 1. è·å–æ‰€æœ‰æ–‡æ¡£
        # all_docs = self.vector_store.documents
        
        # # 2. è¿‡æ»¤æ‰è¦åˆ é™¤çš„æ–‡ä»¶å¯¹åº”çš„æ–‡æ¡£
        # remaining_docs = [doc for doc in all_docs if not doc.metadata.get("source", "").endswith(filename)]
        
        # # 3. é‡å»ºç´¢å¼•
        # self.vector_store = FAISS.from_documents(remaining_docs, self.embeddings)
        # print(f"âœ… æ–‡ä»¶ '{filename}' å·²ä»çŸ¥è¯†åº“ä¸­åˆ é™¤ï¼")
        
        # # 4. ä¿å­˜æ›´æ–°åçš„ç´¢å¼•
        # self._save_vector_store()
        
        # 1. ç®€å•ç²—æš´æ–¹æ¡ˆï¼šæ¸…ç©ºå†…å­˜é‡Œçš„ç´¢å¼•
        self.vector_store = None
        
        # 2. é‡æ–°æ‰«æ uploads æ–‡ä»¶å¤¹é‡Œçš„æ‰€æœ‰ PDF é‡å»º
        # (çœŸå®ç”Ÿäº§ç¯å¢ƒä¼šç”¨ delete by IDï¼Œä½† FAISS ç®€å•ç‰ˆä¸æ”¯æŒï¼Œé‡å»ºæœ€ç¨³)
        uploads_dir = "uploads"
        if os.path.exists(uploads_dir):
            files = [f for f in os.listdir(uploads_dir) if f.endswith(".pdf") and f != filename]
            
            # å¦‚æœè¿˜æœ‰å…¶ä»–æ–‡ä»¶ï¼Œå°±é‡æ–°æŠŠå®ƒä»¬åŠ è¿›å»
            for f in files:
                self.add_pdf(os.path.join(uploads_dir, f))
                
        # å¦‚æœåˆ å…‰äº†ï¼Œè®°å¾—æŠŠæœ¬åœ°çš„ç´¢å¼•æ–‡ä»¶ä¹Ÿåˆ äº†
        if not self.vector_store and os.path.exists(self.vector_store_path):
            import shutil
            shutil.rmtree(self.vector_store_path)
    
    # ğŸ”´ ä¹Ÿå°±æ˜¯æŠŠåŸæ¥çš„ chat æ–¹æ³•æ”¹é€ æˆä¸‹é¢è¿™æ ·
    def chat_stream(self, question: str , model_name: str="deepseek-chat"):
        if not self.vector_store:
            yield "çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼"
            return
            
        # 1. æ£€ç´¢ (å’Œä»¥å‰ä¸€æ ·)
        docs = self.vector_store.similarity_search(question, k=2)
        context = "\n".join([d.page_content for d in docs])
        prompt = f"å·²çŸ¥ä¿¡æ¯ï¼š\n{context}\n\nç”¨æˆ·é—®é¢˜ï¼š{question}\nè¯·æ ¹æ®å·²çŸ¥ä¿¡æ¯å›ç­”ã€‚"
        
        # # 2. è°ƒç”¨ LLM (å¼€å¯æµå¼æ¨¡å¼!)
        # # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç›´æ¥å¾ªç¯ llm.streamï¼Œè€Œä¸æ˜¯ invoke
        # for chunk in self.llm.stream(prompt):
        #     content = chunk.content
        #     if content:
        #         # yield å°±åƒæ˜¯â€œæŒ¤ç‰™è†â€ï¼ŒæŒ¤ä¸€ç‚¹å‡ºæ¥ç»™å¤–é¢
        #         yield content
        
        # åŠ¨æ€åˆ‡æ¢é€»è¾‘
        # å¦‚æœå‰ç«¯ä¼ æ¥çš„æ¨¡å‹åï¼Œä¸åœ¨æˆ‘ä»¬çš„é…ç½®è¡¨é‡Œï¼Œå°±ç”¨é»˜è®¤çš„ deepseek-chat
        if model_name not in self.model_config:
            yield f"âš ï¸ æ¨¡å‹ {model_name} æœªé…ç½®ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ deepseek-chatã€‚"
            model_name = "deepseek-chat"
            
        # 2. åŠ¨æ€åˆ›å»ºæ¨¡å‹
        print(f"ğŸ”„ å½“å‰è¯·æ±‚ä½¿ç”¨æ¨¡å‹: {model_name}")
        try:
            target_llm = self._create_llm(model_name)

            for chunk in target_llm.stream(prompt):
                content = chunk.content
                if content:
                    yield content
        except Exception as e:
            yield f"âŒ è°ƒç”¨æ¨¡å‹å¤±è´¥: {e}"

# # å®ä¾‹åŒ–ä¸€ä¸ªå…¨å±€å¯¹è±¡ä¾›å¤§å®¶è°ƒç”¨
# rag_service = RAGService(
#     api_key=os.getenv("DEEPSEEK_API_KEY"),
#     base_url=os.getenv("DEEPSEEK_BASE_URL")
# )

# ğŸ†• é‡æ„ï¼šå®ä¾‹åŒ–
rag_service = RAGService()