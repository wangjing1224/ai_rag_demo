import os
from dotenv import load_dotenv
import streamlit as st
# 1. è¿™é‡Œæ”¹äº†ï¼š
from langchain_openai import ChatOpenAI
from langchain_community.embeddings import HuggingFaceEmbeddings

from langchain_community.vectorstores import FAISS
from langchain_text_splitters import CharacterTextSplitter
from langchain_core.documents import Document

st.set_page_config(page_title="æˆ‘çš„ AI çŸ¥è¯†åº“", page_icon="ğŸ¤–")
st.title("ğŸ¤– ä¼ä¸šçŸ¥è¯†åº“é—®ç­” Demo")

# --- ä¿®æ”¹å¼€å§‹ ---
# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# 2. è·å– Key (ä¸å†æ˜¯ç¡¬ç¼–ç çš„å­—ç¬¦ä¸²äº†)
API_KEY = os.getenv("DEEPSEEK_API_KEY")
BASE_URL = os.getenv("DEEPSEEK_BASE_URL")

# 3. å®‰å…¨æ£€æŸ¥
if not API_KEY:
    st.error("âš ï¸ æŠ¥é”™ï¼šæœªæ‰¾åˆ° API Keyï¼è¯·ç¡®ä¿ä½ åˆ›å»ºäº† .env æ–‡ä»¶å¹¶é…ç½®äº† DEEPSEEK_API_KEYã€‚")
    st.stop()
# --- ä¿®æ”¹ç»“æŸ ---

knowledge_base_content = """
ã€å…¬å¸ä½œæ¯æ—¶é—´ã€‘
1. ä¸Šç­æ—¶é—´ï¼šä¸Šåˆ 9:30 - ä¸‹åˆ 6:30ã€‚
2. åˆä¼‘æ—¶é—´ï¼šä¸­åˆ 12:00 - 14:00 (ä¸¤å°æ—¶)ã€‚
3. è¿Ÿåˆ°æ”¿ç­–ï¼šæ¯æœˆå…è®¸è¿Ÿåˆ° 3 æ¬¡ï¼Œè¶…è¿‡ 3 æ¬¡æ¯æ¬¡æ‰£ 50 å…ƒã€‚
ã€ç¦åˆ©æ”¿ç­–ã€‘
1. é›¶é£ŸæŸœï¼šæ¯å±‚æ¥¼èŒ¶æ°´é—´æ— é™ä¾›åº”é›¶é£Ÿå’Œå¿«ä¹æ°´ã€‚
2. ç”Ÿæ—¥ç¦åˆ©ï¼šå‘˜å·¥ç”Ÿæ—¥å½“å¤©å¯æå‰ 2 å°æ—¶ä¸‹ç­ï¼Œå¹¶é¢†å– 200 å…ƒå¡ã€‚
3. å›¢å»ºï¼šæ¯å­£åº¦ä¸€æ¬¡éƒ¨é—¨èšé¤ï¼Œäººå‡é¢„ç®— 150 å…ƒã€‚
"""

@st.cache_resource
def load_db():
    text_splitter = CharacterTextSplitter(separator="\n", chunk_size=100, chunk_overlap=10)
    docs = [Document(page_content=x) for x in text_splitter.split_text(knowledge_base_content)]
    
    # 2. è¿™é‡Œæ”¹äº†ï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œè€Œä¸æ˜¯ API
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    
    return FAISS.from_documents(docs, embeddings)

llm = ChatOpenAI(
    api_key=API_KEY,
    base_url=BASE_URL,
    model="deepseek-chat",
    temperature=0.1
)

if "history" not in st.session_state:
    st.session_state.history = []

for msg in st.session_state.history:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("è¯·è¾“å…¥é—®é¢˜..."):
    st.session_state.history.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    
    db = load_db()
    docs = db.similarity_search(prompt, k=2)
    context = "\n".join([d.page_content for d in docs])
    
    final_prompt = f"å·²çŸ¥ä¿¡æ¯ï¼š\n{context}\n\nç”¨æˆ·é—®é¢˜ï¼š{prompt}\nè¯·æ ¹æ®å·²çŸ¥ä¿¡æ¯å›ç­”ï¼Œä¸çŸ¥é“å°±è¯´ä¸çŸ¥é“ã€‚"
    
    response = llm.invoke(final_prompt).content
    st.chat_message("assistant").write(response)
    st.session_state.history.append({"role": "assistant", "content": response})